<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Práctica de métodos no experimentales</title>
    <meta charset="utf-8" />
    <meta name="author" content="Irvin Rojas" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs/cide.css" type="text/css" />
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap-grid.min.css" type="text/css" />
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" type="text/css" />
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: title-slide



.title[
# Clase 5. Práctica de métodos no experimentales
]
.subtitle[
## Evaluación de Programas
]
.author[
### Irvin Rojas &lt;br&gt; [rojasirvin.com](https://www.rojasirvin.com/) &lt;br&gt; [&lt;i class="fab fa-github"&gt;&lt;/i&gt;](https://github.com/rojasirvin) [&lt;i class="fab fa-twitter"&gt;&lt;/i&gt;](https://twitter.com/RojasIrvin) [&lt;i class="ai ai-google-scholar"&gt;&lt;/i&gt;](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&amp;hl=en)
]

.affiliation[
### Centro de Investigación y Docencia Económicas &lt;br&gt; División de Economía
]

---
# Agenda

Usaremos nuestros conocimientos sobre métodos no experimentales en dos aplicaciones 

En ambas notaremos que usamos la regresión como herramienta para la estimación del tamaño de los efectos

Recordemos que la regresión por sí sola no resuelve el problema de identificación del efecto causal, es el diseño del estudio lo que nos permite sentar las bases para la estimación de dichos efectos

---

class: inverse, middle, center

# Diseños con discontinuidades

---

# Discontinuidades nítidas
 
Explotamos el hecho de que el tratamiento es una función determinística de una variable `\(x\)`


$$
D_i =
`\begin{cases}
1  &amp; \mbox{if } x_i \geq x_0 \\
0  &amp; \mbox{if } x_i &lt; x_0
\end{cases}`
$$


`\(x_0\)` es el *umbral* o *corte*

`\(D_i\)` es una función determinística de `\(x_i\)` pues una vez que conocemos `\(x_i\)` entonces conocemos `\(D_i\)`

A diferencia de los modelos de regresión o de pareamiento, no hay valor de `\(x_i\)` en el que observemos a individuos tratados y no tratados
 
La interpretación del efecto estimado por RD es un efecto local en la vecindad de `\(x_0\)`, donde podemos tener confianza que los individuos tratados y no tratados son similares en todas las dimensiones excepto en su posición respecto a `\(x_0\)`
 
Una especificación flexible permite no confundir una discontinuidad con una no linealidad

---

# Un programa de combate a la pobreza

El archivo *datos_pobreza.csv* contiene datos de 2,810 municipios de cierto país

Un programa otorgó fondos de su componente de salud a todos los municipios con un índice de pobreza superior a 59.1968


```r
setwd("C:/Users/rojas/Dropbox/presentations_sites/curso_conl2021/data")

data.hs &lt;- read_csv("./datos_pobreza.csv")
x0 &lt;- 59.1968
```

La variable **mort_age59_related_postHS** indica la mortalidad infantil en cada municipio

La variable **povrate60** es el índice de pobreza para cada municipio

Se desea estimar el efecto del programa en la mortalidad infantil empleando un diseño de regresión discontinua

---

# Variables

Algunas de las variables que usaremos son

**mort_age59_related_postHS** la mortalidad en niños de 5 a 9 años

**povrate60** el porcentaje de la población que vive en pobreza en el municipio

**census1960_pop** la población del municipio

**census1960_pcturban** el porcentaje de la población urbana

**census1960_pctblack** el porcentaje de la población de raza negra


---

# Evidencia gráfica

.pull-left[
Usaremos el paquete *rdrobust*

Recuerden que antes de usar un paquete debemos instalarlo y llamarlo

¿Cuáles eran las funciones para instalar y llamar paquetes?

Construyamos el gráfico correspondiente

]

.pull-right[
![](figures/unnamed-chunk-2-1.png)&lt;!-- --&gt;

```
## Call: rdplot
## 
## Number of Obs.                 2783
## Kernel                      Uniform
## 
## Number of Obs.                 2489             294
## Eff. Number of Obs.            2489             294
## Order poly. fit (p)               1               1
## BW poly. fit (h)             43.988          22.373
## Number of bins scale          1.000           1.000
```
]


---

# Evidencia gráfica

.pull-left[

Especificamos el eje `\(y\)`: la mortalidad

Especificamos el eje `\(x\)`: el índice de pobreza

Especificamos el límite de elegibilidad `\(x_0\)`

*nbins* es el número de puntos a graficar

*p* es el orden del polinomio




```r
(rdplot(y = data.hs$mort_age59_related_postHS,
        x = data.hs$povrate60,
        c = x0,
        nbins = 40,
        p = 1))
```

]

.pull-right[
![](figures/unnamed-chunk-4-1.png)&lt;!-- --&gt;

```
## Call: rdplot
## 
## Number of Obs.                 2783
## Kernel                      Uniform
## 
## Number of Obs.                 2489             294
## Eff. Number of Obs.            2489             294
## Order poly. fit (p)               1               1
## BW poly. fit (h)             43.988          22.373
## Number of bins scale          1.000           1.000
```
]

---

# Evidencia gráfica

.pull-left[

Podemos cambiar el orden del polinomio para permitir no linealidades

Un polinomio de orden dos significa que estimamos un modelo del tipo

`$$y_i=\alpha + \tau pobre_i + \beta_1 indice_i + \beta_2 indice_i^2+\varepsilon_i$$`

Recuerden que `\(\tau\)` es una medida del salto en el valor esperado



```r
(rdplot(y = data.hs$mort_age59_related_postHS,
        x = data.hs$povrate60,
        c = x0,
        nbins = 40,
        p = 2))
```

]

.pull-right[
![](figures/unnamed-chunk-6-1.png)&lt;!-- --&gt;

```
## Call: rdplot
## 
## Number of Obs.                 2783
## Kernel                      Uniform
## 
## Number of Obs.                 2489             294
## Eff. Number of Obs.            2489             294
## Order poly. fit (p)               2               2
## BW poly. fit (h)             43.988          22.373
## Number of bins scale          1.000           1.000
```
]


---

# Estimación paramétrica


La estimación paramétrica nos permite cuantificar el tamaño del salto y calcular su error estándar

Con nuestros datos, vamos a crear una nueva variable

La variable *ispoor* será 1 si el municipio es pobre y 0 si no lo es

Noten como usamos *mutate* para añadir una columna

Usamos *ifelse* para condicionar el valor de la nueva columna **ispoor**



```r
data.hs &lt;- data.hs %&gt;% 
  mutate(ispoor=ifelse(povrate60&gt;=x0,1,0))
```

Recuerden que tenemos que decidir qué tan cerca del corte `\(x_0\)` vamos a centrar el análisis: el ancho de ventana


```r
b &lt;- 10
```



---

# Estimación paramétrica

.pull-left[

Estimaremos entonces el siguiente modelo usando una regresión lineal

`$$y_i=\alpha + \tau pobre_i + \beta_1 indice_i + \beta_2 +\varepsilon_i$$`

Usamos *lm*, como aprendimos antes con el análisis experimental


```r
summary(lm(mort_age59_related_postHS ~ povrate60 + ispoor,
           data=filter(data.hs,
                       povrate60&gt;=x0-b &amp; povrate60&lt;=x0+b)))
```

¿Cómo interpretamos el coeficiente sobre *ispoor*?

]



.pull-right[

```
## 
## Call:
## lm(formula = mort_age59_related_postHS ~ povrate60 + ispoor, 
##     data = filter(data.hs, povrate60 &gt;= x0 - b &amp; povrate60 &lt;= 
##         x0 + b))
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.479 -2.905 -2.331  1.774 61.686 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) -1.63212    4.43998  -0.368   0.7133  
## povrate60    0.08643    0.08188   1.056   0.2916  
## ispoor      -1.53264    0.89167  -1.719   0.0862 .
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.409 on 568 degrees of freedom
##   (4 observations deleted due to missingness)
## Multiple R-squared:  0.006279,	Adjusted R-squared:  0.00278 
## F-statistic: 1.795 on 2 and 568 DF,  p-value: 0.1671
```
]

---

# Validación de los supuestos

.pull-left[
El supuesto clave en el diseño con discontinuidades es que en la vecindad del corte de elegibilidad es como si hubiéramos tenido un experimento

Entonces, el resto de características de los municipios no deberían variar alrededor de `\(x_0\)`

Podemos mostrar esto gráficamente


```r
#Población: census1960_pop
(rdplot(y = data.hs$census1960_pop,
        x = data.hs$povrate60,
        c = x0,
        nbins = 40,
        p = 3))
```

]


.pull-right[
![](figures/unnamed-chunk-12-1.png)&lt;!-- --&gt;

```
## Call: rdplot
## 
## Number of Obs.                 2804
## Kernel                      Uniform
## 
## Number of Obs.                 2504             300
## Eff. Number of Obs.            2504             300
## Order poly. fit (p)               3               3
## BW poly. fit (h)             43.988          33.875
## Number of bins scale          1.000           1.000
```
]

---

# Ejercicio 1

Estimemos ahora el modelo con discontinuidades con una ventana de
  - 15 puntos
  - 5 puntos

Ahora agreguemos un polinomio de orden 3 y una ventana de 10 puntos a la estimación paramétrica

¿Cómo verificaríamos paramétricamente que la población de los municipios efectivamente no cambia de forma discontinua en el corte de elegibilidad?

---

# Checklist

En un diseño con discontinuidades pongamos atención en:

**Supuesto clave**: las características de las unidades varían de forma suave a través del corte

1. Identificar el corte de elegibilidad
  - No debe ser manipulable
  - Las unidades no pueden elegir su posición
  
1. Verificar gráficamente la presencia de una discontinuidad
  - Permitir no linealidades
  
1. Estimar el efecto paramétricamente usando regresión
  - Juzgar la magnitud y significancia estadística
  
1. Verificar que las características observables de las unidades no varía de manera discontinua


---

class: inverse, middle, center

# PSM

---

# Propensity Score Matching

Las técnicas de PSM dependen de varios supuestos estadísticos fuertes

Asumimos que el tratamiento es independiente de `\(y\)` condicional en las variables observables usadas para estimar el PS

Debemos estimar el PS, la probabilidad de ser tratado dado `\(X\)`

Debemos escoger un algoritmo de emparejamiento para consruir el contrafactual

La crítica más importante es que la mayoría de las veces nos preocupa más la autoselección basada en no observables que en observables

Hay que hacer análisis de sensibilidad a las distintas decisiones


---

# Efecto de fumar en el peso de bebés
 
Usamos los datos en *cattaneo_smoking.csv* (Cattaneo, 2010)
 
Crearemos la variable de tratamiento **smoke** que es un indicador de si la madre fumó durante el embarazo
 
El 19% de los mujeres reportaron fumar
 
Usaremos un subconjunto de las `\(X\)` disponibles para modelar el PS

---

# Creamos nuevas variables

.pull-left[

Usemos los datos que están en el archivo *data_peso.csv*


```r
setwd("C:/Users/rojas/Dropbox/presentations_sites/curso_conl2021/data")

data.smoking &lt;- read_csv("./datos_peso.csv") %&gt;% 
  mutate(smoke=ifelse(mbsmoke=="smoker",1,0)) %&gt;% 
  mutate(married=ifelse(mmarried=="married",1,0)) %&gt;% 
  mutate(firstbaby=ifelse(fbaby=="Yes",1,0))
```
]

.pull-right[
*mutate* indica que vamos a modificar el data frame que tenemos a la mano

*ifelse* indica la condición que se debe cumplir para darle un valor a la nueva variable

*ifesle* requiere tres argumentos: la condición, el valor si la condición se cumple y el valor si no se cumple

]

---

# Variables

Algunas variables usa usaremos son

**smoke** indica si la madre fumó o no durante el embarazo

**bweight** peso del bebé al nacer

**married** indicador de casada

**firstbaby** indicador de primer bebé

**medu** educación de la madre

**nprenatal** visitas de cuidado prenatal

**foreign** si la madre nació en el extrnajero

**mhisp** si la madre es hispana

**fage** edad del padre

---

# Diferencias simples

Notemos que, si solo comparamos a las mujeres que fuman con las que no fuman, estamos comparando personas muy diferentes

La función *zelig* nos permite hacer lo mismo que *lm* y algunas cosas más


```r
zelig(bweight ~ smoke, model="ls", data=data.smoking)

zelig(married ~ smoke, model="ls", data=data.smoking)

zelig(medu ~ smoke, model="ls", data=data.smoking)
```

---

# Breve introducción a modelos variable dependiente binaria

`\(y_i\)` toma el valor de 1 si el evento se realiza y 0 si no

$$
y_i=
`\begin{cases}
1 \quad\text{con probabilidad }p \\
0 \quad\text{con probabilidad }1-p
\end{cases}`
$$
Le damos un modelo a `\(p_i\)` con una serie de características `\(x_i\)`

A diferencia de la regresión lineal, aquí especificamos un modelo no lineal porque queremos que la probabilidad estimada quede acotada entre 0 y 1

`$$p_i=F(y_i=1|x_i)=F(x_i'\beta)$$`

La forma que escojamos para `\(F(\cdot)\)` da lugar a los dos modelos más usados: probit y logit

---

# Estimación del PS

.pull-left[
En PSM usamos modelos de probabilidad para estimar el PS, la probabiliad de ser tratado, en función de una serie de características observables

Podemos visualizar la probabilidad de fumar en función de la edad

Vemos que los modelos probit y logit dan resultados muy parecidos en términos de probabilidad ajustada

Para la estimación del PS usaremos varias características para obtener la probabilidad ajustada de haber fumado



]

.pull-right[
![](figures/unnamed-chunk-16-1.png)&lt;!-- --&gt;
]



---


# Efectuamos el matching

.pull-left[

Necesitamos instalar y cargar el paquete *MatchIt* (noten las mayúsculas)


```r
m.out &lt;- matchit(formula=smoke ~ married + firstbaby + medu + nprenatal + foreign + mhisp + fage,
                 method = "nearest",
                 ratio = 1,
                 distance= "logit",
                 replace = FALSE,
                 data = data.smoking)
```

El resumen del procedimiento da bastante información sobre el pareamiento:


```r
summary(m.out)
```
]

.pull-right[
*formula* indica el modelo del PS

*method* indica el algoritmo de emparejamiento a usar

*ratio* indica el número de vecinos

*distance* indica si usamos logit o probit para estimar el PS

*replace* indica si hacemos el emparejamiento con o sin remplazo

*data* indica el data frame a usar

]


---

# Gráfico del traslape

.pull-left[

```r
plot(m.out, type = "jitter")
```

Cada punto es una observación

El eje `\(x\)` es el PS estimado

Nos permite observar el rango estimado de PS y las zonas donde tenemos tratados y no tratados
]

.pull-right[
![](figures/unnamed-chunk-20-1.png)&lt;!-- --&gt;

```
## [1] "To identify the units, use first mouse button; to stop, use second."
```

```
## integer(0)
```
]


---

# Histograma

.pull-left[

```r
plot(m.out, type = "hist")
```

Un histograma es un gráfico que nos indica cuántas observaciones hay para cada nivel de PS

Noten que la primera columna nos dice la distribución del PS en la muestra sin emparejar

La segunda columna nos da la distribución después del emparejamiento

]

.pull-right[
![](figures/unnamed-chunk-22-1.png)&lt;!-- --&gt;
]

---

# Muestra emparejada

El objeto *m.out* contiene toda la información del procedimiento de emparejamiento


```r
m.data &lt;- match.data(m.out)

#Esta matriz nos dice quién es el match de quién
head(m.out$match.matrix)
```

```
##    [,1]  
## 11 "4130"
## 20 "2234"
## 25 "1740"
## 43 "2857"
## 47 "305" 
## 49 "1442"
```


---

# Muestra emparejada

Si ejecutamos lo siguiente, obtendremos un resumen

Pongamos atención al balance de los covariables


```r
summary(m.out)
```

Una regla de dedo para decir que tenemos un buen balance de los covariables en la muestra emparejada es que la diferencia de la media estandarizada (*Std. Mean Diff.*) sea menor que 0.1

---

# Efecto de tratamiento

.tiny[
.pull-left[
Ya que tenemos una muestra donde las características son iguales entre grupos, podemos hacer una comparación entre tratados y no tratados

La función *zelig* lee los objetos generados por el procedimiento de emparejamiento


```r
z.out &lt;- zelig(bweight~smoke,
               data = m.data,
               model = "ls")
```

¿Cómo interpretamos la magnitud y la significancia estadística del efecto estimado?
]
]

.tiny[
.pull-right[

```r
z.out
```

```
## Model: 
## 
## Call:
## z5$zelig(formula = bweight ~ smoke, data = m.data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2740.66  -330.66    41.95   381.95  1880.34 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  3332.05      20.37 163.588  &lt; 2e-16
## smoke        -194.39      28.81  -6.749 2.03e-11
## 
## Residual standard error: 598.7 on 1726 degrees of freedom
## Multiple R-squared:  0.02571,	Adjusted R-squared:  0.02514 
## F-statistic: 45.54 on 1 and 1726 DF,  p-value: 2.033e-11
## 
## Next step: Use 'setx' method
```
]
]


---

# Caliper
.tiny[
.pull-left[
Pasemos ahora a estimar el efecto usando un caliper de 0.1 y dos vecinos

```r
m.out &lt;- matchit(formula=smoke ~ married + firstbaby + medu + nprenatal + foreign + mhisp + fage,
                 method = "nearest",
                 distance= "logit",
                 replace = FALSE,
                 ratio = 2,
                 caliper = .1,
                 data = data.smoking)
```
]
]

.tiny[
.pull-right[

```r
zelig(bweight~smoke,
               data = match.data(m.out),
               model = "ls")
```

```
## How to cite this model in Zelig:
##   R Core Team. 2007.
##   ls: Least Squares Regression for Continuous Dependent Variables
##   in Christine Choirat, Christopher Gandrud, James Honaker, Kosuke Imai, Gary King, and Olivia Lau,
##   "Zelig: Everyone's Statistical Software," https://zeligproject.org/
```

```
## Model: 
## 
## Call:
## z5$zelig(formula = bweight ~ smoke, data = match.data(m.out))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2907.56  -328.56    38.44   387.76  1880.76 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  3361.56      14.94 225.048   &lt;2e-16
## smoke        -224.31      25.21  -8.899   &lt;2e-16
## 
## Residual standard error: 596.2 on 2453 degrees of freedom
## Multiple R-squared:  0.03127,	Adjusted R-squared:  0.03088 
## F-statistic: 79.18 on 1 and 2453 DF,  p-value: &lt; 2.2e-16
## 
## Next step: Use 'setx' method
```
]
]

---

# Muestra emparejada

Noten que en la muestra emparejada ahora tenemos dos individuos para cada tratado

En algunos casos no hubo dos emparejados porque no había nadie dentro del caliper


```r
m.data &lt;- match.data(m.out)

#Esta matriz nos dice quién es el match de quién
head(m.out$match.matrix)
```

```
##    [,1]   [,2]  
## 11 "4130" "2791"
## 20 "2234" NA    
## 25 "1740" "2259"
## 43 "2857" "1822"
## 47 "305"  "3931"
## 49 "1442" "4306"
```

---

# Ejercicio 2

Estimemos el efecto de tratamiento usando PSM con las siguientes modificaciones

- Incluya el cuadrado de la edad del padre **fage** y la educación de la madre *medu*

- Use un caliper de 0.15

- Use tres vecinos dentro del caliper

---

# Checklist

En un diseño con PSM pongamos atención en:

**Supuesto clave**: condicional en las características **observables** de las unidades, el tratamiento es independiente de la variable de resultados

1. Determinar el conjunto de variables que se usarán para estimar el PS
  - No deben de haber sido afectadas por el tratamiento

1. Estimar el PS usando logit o probit

1. Usar un algoritmo de emparejamiento

1. Verificar la propiedad de balance
  - La función principal del PS es construir una muestra emparejada balanceada
  
1. Estimar el efecto de tratamiento en la muestra emparejada

1. Mostrar la robustez de los resultados
  - Distintas especificaciones del PS
  - Distintos algoritmos de emparejamiento

---

# Conclusión del módulo

En este módulo cubrimos conceptos de evaluación experimental y no experimental

Enfatizamos que una evaluación se sostiene en tres pilares
  - Pregunta motivada en la teoría
  - Diseño apropiado para el contexto
  - Herramientas estadísticas
  
Debemos poner atención a los supuestos que sostienen una estrategia de evaluación

Los métodos experimentales requieren menos supuestos, pero tienen varias desventajas

Los métodos no experimentales requieren más supuestos, pero a veces son las únicas alternativas factibles

Las evaluaciones deben ser lo más transparentes posibles, mostrando la robustez a todas las decisiones tomadas

Debemos ser críticos no solo con los efectos estimados y su significancia estadística, sino con la credibilidad de los supuestos asumidos


---

class: center, middle

Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script src="libs/cols_macro.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
